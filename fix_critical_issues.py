#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤é¡¹ç›®ä¸­çš„ä¸¥é‡é—®é¢˜
1. ä¿®å¤URLæ ¼å¼é”™è¯¯ (https:///)
2. æ›¿æ¢å ä½ç¬¦åŸŸå (your-domain.com)
3. æ¸…ç†æµ‹è¯•æ–‡ä»¶
4. é‡æ–°ç”Ÿæˆsitemap
"""

import os
import glob
import re
from datetime import datetime

def fix_url_format_issues():
    """ä¿®å¤æ‰€æœ‰URLæ ¼å¼é—®é¢˜"""
    
    # è·å–æ‰€æœ‰HTMLæ–‡ä»¶
    html_files = glob.glob('*.html') + glob.glob('*/**/*.html', recursive=True)
    
    fixed_count = 0
    url_fixes = 0
    
    for file_path in html_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            modified = False
            
            # ä¿®å¤ https:/// æ ¼å¼çš„URL
            patterns_to_fix = [
                (r'href="https:///([^"]*)"', r'href="https://growagarden.cv/\1"'),
                (r'content="https:///([^"]*)"', r'content="https://growagarden.cv/\1"'),
                (r'src="https:///([^"]*)"', r'src="https://growagarden.cv/\1"'),
                (r'url": "https:///([^"]*)"', r'url": "https://growagarden.cv/\1"'),
            ]
            
            for pattern, replacement in patterns_to_fix:
                if re.search(pattern, content):
                    content = re.sub(pattern, replacement, content)
                    modified = True
                    url_fixes += 1
            
            # æ›¿æ¢å ä½ç¬¦åŸŸå
            placeholder_fixes = [
                (r'your-domain\.com', 'growagarden.cv'),
                (r'https://your-domain\.com', 'https://growagarden.cv'),
            ]
            
            for old, new in placeholder_fixes:
                if re.search(old, content):
                    content = re.sub(old, new, content)
                    modified = True
                    url_fixes += 1
            
            # å¦‚æœå†…å®¹æœ‰ä¿®æ”¹ï¼Œä¿å­˜æ–‡ä»¶
            if modified:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                fixed_count += 1
                print(f"âœ… ä¿®å¤ {file_path}: {url_fixes} ä¸ªURLé—®é¢˜")
                
        except Exception as e:
            print(f"âŒ å¤„ç† {file_path} æ—¶å‡ºé”™: {str(e)}")
    
    print(f"\nğŸ‰ URLæ ¼å¼ä¿®å¤å®Œæˆï¼å…±ä¿®å¤äº† {fixed_count} ä¸ªæ–‡ä»¶ï¼Œ{url_fixes} ä¸ªURLé—®é¢˜")
    return fixed_count

def clean_test_files():
    """æ¸…ç†æ‰€æœ‰æµ‹è¯•æ–‡ä»¶"""
    
    # è¦åˆ é™¤çš„æµ‹è¯•æ–‡ä»¶æ¨¡å¼
    test_patterns = [
        'test_*.html',
        'test_*.js',
        'preview.html',
        'debug_*.html',
        'force_refresh.html'
    ]
    
    deleted_files = []
    
    for pattern in test_patterns:
        files = glob.glob(pattern)
        for file_path in files:
            try:
                os.remove(file_path)
                deleted_files.append(file_path)
                print(f"ğŸ—‘ï¸ åˆ é™¤æµ‹è¯•æ–‡ä»¶: {file_path}")
            except Exception as e:
                print(f"âŒ åˆ é™¤ {file_path} æ—¶å‡ºé”™: {str(e)}")
    
    print(f"\nğŸ§¹ æµ‹è¯•æ–‡ä»¶æ¸…ç†å®Œæˆï¼å…±åˆ é™¤ {len(deleted_files)} ä¸ªæ–‡ä»¶")
    return deleted_files

def clean_scripts_directory():
    """æ•´ç†è„šæœ¬ç›®å½•"""
    
    # åˆ›å»ºscriptsç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if not os.path.exists('scripts'):
        os.makedirs('scripts')
        print("ğŸ“ åˆ›å»ºscriptsç›®å½•")
    
    # ç§»åŠ¨Pythonè„šæœ¬åˆ°scriptsç›®å½•
    python_scripts = glob.glob('*.py')
    moved_scripts = []
    
    for script in python_scripts:
        if script != 'fix_critical_issues.py':  # ä¿ç•™å½“å‰è„šæœ¬
            try:
                new_path = os.path.join('scripts', script)
                os.rename(script, new_path)
                moved_scripts.append(script)
                print(f"ğŸ“¦ ç§»åŠ¨è„šæœ¬: {script} -> scripts/{script}")
            except Exception as e:
                print(f"âŒ ç§»åŠ¨ {script} æ—¶å‡ºé”™: {str(e)}")
    
    print(f"\nğŸ“¦ è„šæœ¬æ•´ç†å®Œæˆï¼å…±ç§»åŠ¨ {len(moved_scripts)} ä¸ªè„šæœ¬åˆ°scriptsç›®å½•")
    return moved_scripts

def regenerate_sitemap():
    """é‡æ–°ç”Ÿæˆsitemap.xml"""
    
    try:
        # è¿è¡Œsitemapç”Ÿæˆè„šæœ¬
        if os.path.exists('scripts/generate_complete_sitemap.py'):
            os.system('python scripts/generate_complete_sitemap.py')
            print("âœ… é‡æ–°ç”Ÿæˆsitemap.xml")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°sitemapç”Ÿæˆè„šæœ¬")
    except Exception as e:
        print(f"âŒ é‡æ–°ç”Ÿæˆsitemapæ—¶å‡ºé”™: {str(e)}")

def create_robots_txt():
    """åˆ›å»º/æ›´æ–°robots.txt"""
    
    robots_content = """User-agent: *
Allow: /

# å…è®¸æ‰€æœ‰æœç´¢å¼•æ“çˆ¬å–
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

# ç«™ç‚¹åœ°å›¾ä½ç½®
Sitemap: https://growagarden.cv/sitemap.xml

# çˆ¬å–å»¶è¿Ÿï¼ˆå¯é€‰ï¼Œé¿å…æœåŠ¡å™¨è¿‡è½½ï¼‰
Crawl-delay: 1

# å…è®¸CSSå’ŒJSæ–‡ä»¶ï¼ˆæœ‰åŠ©äºé¡µé¢æ¸²æŸ“ï¼‰
Allow: /*.css
Allow: /*.js
Allow: /*.png
Allow: /*.jpg
Allow: /*.jpeg
Allow: /*.gif
Allow: /*.svg

# ç¦æ­¢çˆ¬å–ç®¡ç†æˆ–ä¸´æ—¶æ–‡ä»¶
Disallow: /admin/
Disallow: /temp/
Disallow: /private/
Disallow: /*.log
Disallow: /*.tmp
Disallow: /scripts/
"""
    
    with open('robots.txt', 'w', encoding='utf-8') as f:
        f.write(robots_content)
    
    print("âœ… æ›´æ–°robots.txt")

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸš€ å¼€å§‹ä¿®å¤é¡¹ç›®ä¸­çš„ä¸¥é‡é—®é¢˜...")
    print("=" * 60)
    
    # 1. ä¿®å¤URLæ ¼å¼é—®é¢˜
    print("\nğŸ”§ æ­¥éª¤1: ä¿®å¤URLæ ¼å¼é—®é¢˜")
    fixed_files = fix_url_format_issues()
    
    # 2. æ¸…ç†æµ‹è¯•æ–‡ä»¶
    print("\nğŸ§¹ æ­¥éª¤2: æ¸…ç†æµ‹è¯•æ–‡ä»¶")
    deleted_files = clean_test_files()
    
    # 3. æ•´ç†è„šæœ¬ç›®å½•
    print("\nğŸ“¦ æ­¥éª¤3: æ•´ç†è„šæœ¬ç›®å½•")
    moved_scripts = clean_scripts_directory()
    
    # 4. é‡æ–°ç”Ÿæˆsitemap
    print("\nğŸ—ºï¸ æ­¥éª¤4: é‡æ–°ç”Ÿæˆsitemap")
    regenerate_sitemap()
    
    # 5. æ›´æ–°robots.txt
    print("\nğŸ¤– æ­¥éª¤5: æ›´æ–°robots.txt")
    create_robots_txt()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ‰ ä¸¥é‡é—®é¢˜ä¿®å¤å®Œæˆï¼")
    print(f"ğŸ“Š ä¿®å¤ç»Ÿè®¡:")
    print(f"   - ä¿®å¤æ–‡ä»¶æ•°: {fixed_files}")
    print(f"   - åˆ é™¤æµ‹è¯•æ–‡ä»¶: {len(deleted_files)}")
    print(f"   - æ•´ç†è„šæœ¬: {len(moved_scripts)}")
    print(f"   - é‡æ–°ç”Ÿæˆsitemap: âœ…")
    print(f"   - æ›´æ–°robots.txt: âœ…")
    
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("1. æµ‹è¯•ç½‘ç«™åŠŸèƒ½æ˜¯å¦æ­£å¸¸")
    print("2. éªŒè¯æ‰€æœ‰URLæ ¼å¼æ­£ç¡®")
    print("3. æ£€æŸ¥sitemap.xmlå†…å®¹")
    print("4. åœ¨æœç´¢å¼•æ“æ§åˆ¶å°é‡æ–°æäº¤sitemap")
    print("5. ç›‘æ§ç´¢å¼•çŠ¶æ€å˜åŒ–")
    
    print(f"\nâ° ä¿®å¤å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main() 